{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification with small data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download and setup dataset (Kaggle Cats & Dogs) https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "2. Train a small convnet on our small data (acc ~ 0.75)\n",
    "3. Train a MLP using bottleneck features of pretrained model (acc ~ 0.90)\n",
    "4. Finetuning top layers of pretrained model on our small data (acc ~ 0.94)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathlizard/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plot & parse functions\n",
    "def parse_log_file(pfile):\n",
    "    f= open(pfile).readlines()\n",
    "    lines = [i.strip() for i in f]\n",
    "    log= {k:[] for k in ['acc','val_acc','loss','val_loss']}\n",
    "    for l in lines:\n",
    "        if 'loss' in l:\n",
    "            for k in log.keys():\n",
    "                log[k].append(float(l.split(k+': ')[1].split(' -')[0]))\n",
    "    return log \n",
    "\n",
    "def plot_loss_acc(pfile):\n",
    "    history = parse_log_file(pfile)\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.title('model acc')\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a small convnet on our small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9248)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                591936    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 611,393\n",
      "Trainable params: 611,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define a sequential model (small conv net): \n",
    "# 3 conv blocks (Conv2D, Activation('relu'), MaxPooling2D) + 2 dense layers\n",
    "# Conv_1: filters 32, kernel size(3,3)\n",
    "# Conv_2: filters 32, kernel size(3,3)\n",
    "# Conv_3: filters 64, kernel size(3,3)\n",
    "# Flatten\n",
    "# Dense_1: 64\n",
    "# Activation('relu')\n",
    "# Dropout(0.5)\n",
    "# Dense_2:  ? \n",
    "# Activation('sigmoid')\n",
    "\n",
    "# print model summary\n",
    "\n",
    "# # add your implementation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(\n",
    "32, (3,3), \n",
    "activation = 'relu',\n",
    "input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(\n",
    "32, (3,3), \n",
    "activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(\n",
    "32, (3,3), \n",
    "activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model \n",
    "# use binary crossentropy loss \n",
    "# and rmsprop optimizer\n",
    "\n",
    "# # add your implementation\n",
    "\n",
    "model.compile(optimizer=optimizers.rmsprop(),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a keras ImageDataGenerator for training data with appropriate augmentation \n",
    "# use rescale=1. / 255 to normalise pixles values\n",
    "\n",
    "# define a keras ImageDataGenerator for test data  (no augmentation only rescaling)\n",
    "\n",
    "# # add your implementation\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# define training and validation iterators \n",
    "# use ImageDataGenerator.flow_from_directory to training and validation dirs accordingly \n",
    "\n",
    "# # add your implementation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 0.6978 - acc: 0.5455 - val_loss: 0.6743 - val_acc: 0.6325\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.6462 - acc: 0.6355 - val_loss: 0.6192 - val_acc: 0.6575\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.5956 - acc: 0.6850 - val_loss: 0.5751 - val_acc: 0.6912\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 0.5538 - acc: 0.7270 - val_loss: 0.5693 - val_acc: 0.7037\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 15s 151ms/step - loss: 0.5175 - acc: 0.7630 - val_loss: 0.5777 - val_acc: 0.6862\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 0.4617 - acc: 0.7840 - val_loss: 0.6068 - val_acc: 0.6988\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 15s 155ms/step - loss: 0.4259 - acc: 0.8000 - val_loss: 0.5474 - val_acc: 0.7238\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 15s 151ms/step - loss: 0.3936 - acc: 0.8240 - val_loss: 0.5485 - val_acc: 0.7425\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 15s 150ms/step - loss: 0.3448 - acc: 0.8460 - val_loss: 0.6967 - val_acc: 0.7050\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.3056 - acc: 0.8670 - val_loss: 0.6313 - val_acc: 0.7387\n"
     ]
    }
   ],
   "source": [
    "# train and validate the model using fit_generator\n",
    "history = model.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch=100,\n",
    "epochs=10,\n",
    "validation_data=validation_generator,\n",
    "validation_steps=50)\n",
    "\n",
    "# # add your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a MLP using bottleneck features\n",
    "### MLP -- multilayer percepton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 22s 0us/step\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# define VGG16 network using keras applications.VGG16  \n",
    "# set weights = 'imagenet'\n",
    "# set include_top=False : don't include the fully-connected layer at the top of the network \n",
    "# set input_shape: image shape\n",
    "\n",
    "# # add your implementation\n",
    "from keras.applications import VGG16\n",
    "\n",
    "vgg_16=VGG16(include_top=False, input_shape=(150,150,3), weights='imagenet')\n",
    "# define a keras ImageDataGenerator for data (no augmentation only rescaling)\n",
    "# define training and validation iterators same as before (set shuffle=False)\n",
    "\n",
    "# # add your implementation\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "# extract image features for training and validation separately using predict_generator\n",
    "\n",
    "# # add your implementation\n",
    "pred_train = vgg_16.predict_generator(train_generator)\n",
    "pred_valid= vgg_16.predict_generator(validation_generator)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4, 4, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save training and validation features\n",
    "\n",
    "# # add your implementation\n",
    "\n",
    "np.save(open('bottleneck_features_train_1.npy', 'wb'), pred_train)\n",
    "np.save(open('bottleneck_features_validation_1.npy', 'wb'), pred_valid)\n",
    "pred_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('training_features.npy', 'wb'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.8516 - acc: 0.7275 - val_loss: 0.4069 - val_acc: 0.7913\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 739us/step - loss: 0.3740 - acc: 0.8280 - val_loss: 0.3307 - val_acc: 0.8438\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 711us/step - loss: 0.2963 - acc: 0.8845 - val_loss: 0.5889 - val_acc: 0.7675\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 2s 756us/step - loss: 0.2555 - acc: 0.8855 - val_loss: 0.2504 - val_acc: 0.9062\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 734us/step - loss: 0.2222 - acc: 0.9110 - val_loss: 0.2520 - val_acc: 0.9050\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 748us/step - loss: 0.2128 - acc: 0.9085 - val_loss: 0.3578 - val_acc: 0.8512\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 733us/step - loss: 0.1904 - acc: 0.9305 - val_loss: 0.2871 - val_acc: 0.9025\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 2s 752us/step - loss: 0.1672 - acc: 0.9375 - val_loss: 0.4132 - val_acc: 0.8638\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 2s 755us/step - loss: 0.1528 - acc: 0.9355 - val_loss: 0.2883 - val_acc: 0.9000\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 724us/step - loss: 0.1227 - acc: 0.9550 - val_loss: 0.2875 - val_acc: 0.9038\n"
     ]
    }
   ],
   "source": [
    "# create training and validation labels array (features are in order because we used shuffle=false) \n",
    "\n",
    "# # add your implementation\n",
    "train_labels = train_generator.classes\n",
    "validation_labels = validation_generator.classes\n",
    "\n",
    "# define model of two dense layers 256 and ? \n",
    "# model should start with Flatten layer (to flatten extracted image features to a vector)\n",
    "# donâ€™t forget activations and dropout(0.5)\n",
    "# compile with binary_crossentropy loss and rmsprop optimizer\n",
    "\n",
    "# # add your implementation\n",
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(4,4,512)))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "# Train MLP using fit function\n",
    "\n",
    "# # add your implementation\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "pred_train,\n",
    "    train_labels,\n",
    "epochs=10,\n",
    "validation_data=(pred_valid, validation_labels))\n",
    "# save weights to use them in fine-tuning later on\n",
    "\n",
    "# # add your implementation\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_path'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_16/Sigmoid:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vgg_16.input\n",
    "model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning top layers of pretrained model on our small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"flatten_8_input:0\", shape=(?, 4, 4, 512), dtype=float32) at layer \"flatten_8_input\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7925aebc137f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvgg_16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# vgg_16.get_layer(index=)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 237\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                                          \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                                          \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                                          str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1431\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                     \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"flatten_8_input:0\", shape=(?, 4, 4, 512), dtype=float32) at layer \"flatten_8_input\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "# define new model:  VGG16 as base and MLP as top \n",
    "# input = base_model.input, output=top_model(base_model.output)\n",
    "\n",
    "# # add your implementation\n",
    "\n",
    "\n",
    "model = Model(inputs= [vgg_16.input], outputs=vgg16[model.output])\n",
    "# vgg_16.get_layer(index=)\n",
    "\n",
    "\n",
    "# freeze the first 15 layers (up to the last conv block)\n",
    "# set trainable=false (weights will not be updated)\n",
    "\n",
    "# # add your implementation\n",
    "\n",
    "# compile with binary_crossentropy loss and SGD with low learing rate optimizer\n",
    "\n",
    "# # add your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune the model using fit_generator and train and validation iterators"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
